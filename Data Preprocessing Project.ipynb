{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffccd4bc-5d40-4eac-a9ce-9b3cac9a9525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      " Feature1    100\n",
      "Feature2      0\n",
      "Feature3     67\n",
      "Feature4      0\n",
      "Feature5      0\n",
      "Target        0\n",
      "dtype: int64\n",
      "\n",
      "Missing values after imputation:\n",
      " Feature1    0\n",
      "Feature2    0\n",
      "Feature3    0\n",
      "Feature4    0\n",
      "Feature5    0\n",
      "Target      0\n",
      "dtype: int64\n",
      "\n",
      "Shape after outlier removal: (986, 6)\n",
      "\n",
      "Train shape: (788, 5)\n",
      "Test shape: (198, 5)\n"
     ]
    }
   ],
   "source": [
    "#  Data Preprocessing Project \n",
    "\n",
    "# Step 1: Import Required Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 2: Generate Synthetic Dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=5, noise=10, random_state=42)\n",
    "df = pd.DataFrame(X, columns=['Feature1', 'Feature2', 'Feature3', 'Feature4', 'Feature5'])\n",
    "df['Target'] = y\n",
    "\n",
    "# Step 3: Add Missing Values and Outliers\n",
    "# Introduce missing values\n",
    "df.loc[::10, 'Feature1'] = np.nan\n",
    "df.loc[::15, 'Feature3'] = np.nan\n",
    "\n",
    "# Introduce outliers\n",
    "df.loc[5, 'Feature2'] = df['Feature2'].mean() + 10 * df['Feature2'].std()\n",
    "df.loc[20, 'Feature4'] = df['Feature4'].mean() - 10 * df['Feature4'].std()\n",
    "\n",
    "# Step 4: Handle Missing Values\n",
    "print(\"Missing values before handling:\\n\", df.isnull().sum())\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "print(\"\\nMissing values after imputation:\\n\", df.isnull().sum())\n",
    "\n",
    "# Step 5: Handle Outliers (column-wise Z-score filtering)\n",
    "for col in df.columns[:-1]:  # Skip 'Target'\n",
    "    z = np.abs(stats.zscore(df[col]))\n",
    "    df = df[z < 3]\n",
    "\n",
    "print(\"\\nShape after outlier removal:\", df.shape)\n",
    "\n",
    "# Step 6: Feature Scaling\n",
    "X = df.drop('Target', axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 7: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"\\nTrain shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)  # Final check\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
